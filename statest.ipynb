{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-26T08:20:20.456759772Z",
     "start_time": "2023-07-26T08:20:20.326881790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats_file = PosixPath('stats/pivot/UD_French-PUD/VERB.xlsx')\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mZeroDivisionError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 91\u001B[0m\n\u001B[1;32m     87\u001B[0m     temp[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfeuilles\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m feuilles\n\u001B[1;32m     89\u001B[0m     stats[corpus][query] \u001B[38;5;241m=\u001B[39m temp\n\u001B[0;32m---> 91\u001B[0m \u001B[38;5;241;43m1\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\n",
      "\u001B[0;31mZeroDivisionError\u001B[0m: division by zero"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def save_to_sheet(df, sheet, writer):\n",
    "    df.to_excel(writer, sheet_name=sheet, index=True, header=True)\n",
    "\n",
    "\n",
    "main = Path(\"Xports\")\n",
    "stats_folder_main = Path(\"stats\")\n",
    "\n",
    "for mode in (\"pivot\", \"LEMMA\"):\n",
    "    stats_folder = stats_folder_main / mode\n",
    "    jsons = list(main.glob(\"*/*.json\"))\n",
    "    jsons = [Path(\"/home/marceau/PycharmProjects/GrewCount/Xports/UD_French-PUD/VERB.json\")]\n",
    "\n",
    "    nb_feuilles = 10\n",
    "\n",
    "    stats = {}\n",
    "\n",
    "    for json in jsons:\n",
    "        corpus = json.parent.name\n",
    "        query = json.stem\n",
    "\n",
    "        stats_file = stats_folder / corpus\n",
    "        stats_file.mkdir(parents=True, exist_ok=True)\n",
    "        stats_file = stats_file / (query + \".xlsx\")\n",
    "\n",
    "        print(f\"{stats_file = }\")\n",
    "\n",
    "        if corpus not in stats:\n",
    "            stats[corpus] = {}\n",
    "        stats[corpus][query] = {}\n",
    "\n",
    "        df = pd.read_json(json)\n",
    "\n",
    "        if len(df) == 0:\n",
    "            print(f\"{json = }\")\n",
    "            print(f\"{df = }\")\n",
    "            continue\n",
    "\n",
    "        verbes = df[mode]\n",
    "        verbes_freq = Counter([e.lower() for e in verbes])\n",
    "        occurences = len(verbes)\n",
    "\n",
    "        # print(df.head())\n",
    "\n",
    "        tuplverbes = sorted([(v, verbes_freq[v]) for v in verbes_freq], key=lambda x: x[1], reverse=True)\n",
    "        tuplverbes = {v: c for v, c in tuplverbes}\n",
    "\n",
    "        temp = {\n",
    "            \"nb_occurences\": occurences,\n",
    "            \"nb_verbes\": len(verbes.unique()),\n",
    "            **tuplverbes,\n",
    "        }\n",
    "\n",
    "        feuilles = {}\n",
    "\n",
    "        for verbe, count in verbes_freq.most_common(nb_feuilles):\n",
    "            phrases = df[df[mode] == verbe]\n",
    "            feuilles[verbe] = {}\n",
    "            feuilles[verbe][\"stats\"] = {\n",
    "                \"nb_occurences\": count,\n",
    "                \"freq\": count / occurences,\n",
    "                \"nb_phrases\": len(phrases),\n",
    "            }\n",
    "\n",
    "            # [(sent_id, left, pivot, right) for sent_id, left, pivot, right in phrases[[\"sent_id\", \"left_context\", \"pivot\", \"right_context\"]].values]\n",
    "            feuilles[verbe][\"phrases\"] = phrases.values.tolist()\n",
    "\n",
    "        with pd.ExcelWriter(stats_file, engine='xlsxwriter') as writer:\n",
    "\n",
    "            tempdf = pd.DataFrame(temp, index=[\"\", ])\n",
    "            tempdf = tempdf.T\n",
    "\n",
    "            save_to_sheet(tempdf, \"Globales\", writer)\n",
    "\n",
    "            for verbe, content in feuilles.items():\n",
    "                tempdf = pd.DataFrame(content[\"stats\"], index=[0])\n",
    "                save_to_sheet(tempdf, f\"{verbe}_stats\", writer)\n",
    "\n",
    "                tempdf = pd.DataFrame(content[\"phrases\"], columns=phrases.columns)\n",
    "                save_to_sheet(tempdf, f\"{verbe}_phrases\", writer)\n",
    "\n",
    "\n",
    "        temp[\"feuilles\"] = feuilles\n",
    "\n",
    "        stats[corpus][query] = temp\n",
    "\n",
    "    1/0\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "for corpus, content in stats.items():\n",
    "    stats[corpus][\"all\"] = {}\n",
    "    for query, content2 in content.items():\n",
    "        if query == \"all\":\n",
    "            continue\n",
    "        for k, v in content2.items():\n",
    "            if k == \"feuilles\":\n",
    "                if k not in stats[corpus][\"all\"]:\n",
    "                    stats[corpus][\"all\"][k] = {}\n",
    "                for verbe, content3 in v.items():\n",
    "                    if verbe not in stats[corpus][\"all\"][k]:\n",
    "                        stats[corpus][\"all\"][k][verbe] = {}\n",
    "                        stats[corpus][\"all\"][k][verbe][\"stats\"] = {}\n",
    "                        stats[corpus][\"all\"][k][verbe][\"phrases\"] = []\n",
    "\n",
    "                    for k2, v2 in content3[\"stats\"].items():\n",
    "                        if k2 not in stats[corpus][\"all\"][k][verbe][\"stats\"]:\n",
    "                            stats[corpus][\"all\"][k][verbe][\"stats\"][k2] = 0\n",
    "\n",
    "                        stats[corpus][\"all\"][k][verbe][\"stats\"][k2] += v2\n",
    "\n",
    "                    stats[corpus][\"all\"][k][verbe][\"phrases\"] += content3[\"phrases\"]\n",
    "\n",
    "            else:\n",
    "                if k not in stats[corpus][\"all\"]:\n",
    "                    stats[corpus][\"all\"][k] = 0\n",
    "\n",
    "                stats[corpus][\"all\"][k] += v\n",
    "\n",
    "    for corpus in stats:\n",
    "        stats_file = stats_folder_main / mode / corpus / \"corpus.xlsx\"\n",
    "        feuilles = stats[corpus][\"all\"][\"feuilles\"]\n",
    "        with pd.ExcelWriter(stats_file, engine='xlsxwriter') as writer:\n",
    "            df = pd.DataFrame(stats[corpus][\"all\"], index=[\"\", ])\n",
    "            df = df.T\n",
    "            save_to_sheet(df, \"Globales\", writer)\n",
    "\n",
    "            for verbe, content_ in feuilles.items():\n",
    "                tempdf = pd.DataFrame(content_[\"stats\"], index=[0])\n",
    "                save_to_sheet(tempdf, f\"{verbe}_stats\", writer)\n",
    "\n",
    "                tempdf = pd.DataFrame(content_[\"phrases\"], columns=phrases.columns)\n",
    "                save_to_sheet(tempdf, f\"{verbe}_phrases\", writer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T08:20:27.128360210Z",
     "start_time": "2023-07-26T08:20:27.054149417Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tempdf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats[\"all\"]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
